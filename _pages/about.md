---
permalink: /
title: "AI Generated Content: Its Creation and Regulations Within the US and Europe"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Artificial intelligence or machine learning-generated content has taken the world by storm. It has appeared in nearly every consumer industry, with many products and services boasting artificial intelligence algorithms to enhance some aspects of their service. This was a massive boom in the industry for machine learning companies and algorithms; especially notable was OpenAI's claim to fame, their easily accessible ChatGPT model, which has been utilized thoroughly in schools, careers, and government agencies. Astonishingly, according to Reuters, there were "1.43 billion" visits to their website in August of 2023, a 3.2% decrease from September (Tong). Although many of those billions of visits and generations are now mainly unregulated by any discernible branch of government, the end user agreement that OpenAI wrote and enforced is practically the only barrier between their machine learning model and their users' whims.

This facet of the industry has been so newly emerged that practically no government has instituted comprehensive legislation concerning the users and outputs of these private, proprietary, "black box" algorithms: "black box" refers to the fact that the operation is largely unknown. This has been causing issues worldwide regarding the moral and legal obligations that the user should have. Using an open-source image-generating algorithm, Stable Diffusion, reports of explicit image creation without the consent of included parties have been a large part of these discussions. Domestically, there have been reports of high school students from New Jersey using AI-powered applications to non-consensually create and share nude approximations of over thirty female classmates; additionally, there was a recent controversy surrounding pop-star Taylor Swift with a series of explicit photos generated and publicized on X, formally Twitter, before being removed after immense backlash (Kelly). Events like these are taking place worldwide, with the perpetrators being unafraid of the consequences due to a lack of regulation. There are also concerns about safety and the distribution of essential services throughout the country if either private businesses or government agencies begin to use these AI models due to their innate disconnection from some humane interface that would be able to correct errors. Suppose machine learning algorithms are used in this context. In that case, there may be higher probabilities o institutionalized bias in the system since the training data would not be able to factor into account systematic inequalities, though according to Reuters, the AI Act passed by the EU should prohibit many of the use cases for these algorithms in those scenarios (Yun Chee). Increasing tensions from these events have pressured legislators to act. Now, bills are being proposed that would set a standard for punitive action against these perpetrators and reparations for the subjects of such content.

I contend that United States legislation will take a better overall approach to regulating and punishing offenders because the United States prioritizes individual rights and because its laws are more comprehensive overall. This difference will be demonstrated with comparisons between human rights laws (mainly referencing copying a person's likeness), copyright laws, and finally, uses in fraud, scams, and phishing.

## Human Rights

To get started, human rights laws can be dissected using Penelope Thornton's article "Deepfakes: An EU and US Perspective" and the United States proposed bill H. R. 5586.
The latter demonstrates the United States' focus on personal cases of non-consensual image generation by denoting the proper procedure and prerequisites to constitute a valid claim of damages suffered under non-consensual image generation of the person's likeness (H. R. 5586). Further, Thornton's article describes some major differences between the United States and European Union's legislation, which is more specific about countries within Europe rather than as a whole.

Many people would agree that the right to a person's likeness should be protected as one of their innate human rights. These rights have come under threat due to non-consensual image generation. To begin with, the world has been suffering an extreme influx of explicit image generation. For my purposes, I will focus on two cases, one of New Jersey students creating nude images of classmates, and the second pertaining to Taylor Swift. Under the United States proposed bill H. R. 5586, these perpetrators would likely be subject to pay $150,000 USD per record or the monetary value of the damages inflicted by the person or persons involved. This payment is reliant on three conditions: first, that the images are found; second, that the perpetrators are also found; otherwise, few protections would prevent those types of images from being generated again or few ways that the perpetrators would be found, and third, that $150,000 is a significant sum to the perpetrator; this would be true for most people, but monetary punishments innately create more incentive for those to whom that amount is a large proportion of their assets than those who have massive wealth therefore punishing the wealthy less for the same crime. If those three conditions are not met, the deterrent for this behavior is simply an annoyance at best, and the behavior may continue.

Conversely, according to Thornton, "there are currently no European laws or national laws in the UK, France or Germany specifically dedicated to tackling deepfakes." Rather, their main route to controlling this is by introducing regulations on disinformation that would then also regulate deepfakes, however the main aim of this legislation is directed towards false news. Instead, victims of this sexual cybercrime are forced to act on a country-by-country basis, which is not a reliable source of support. For example, in the United Kingdom, France, and Germany there are national laws on defamation that may be able to be applied to deepfakes, however those as well are directed more towards content that would be seen to harm someone’s reputation; in this way, there may be situations where this would not protect the victim since its creation was not outlawed simply how it would be used, and it is a similar situation with deepfakes as well. Thornton specifically points out, “in the UK…if a person wants to prevent the use of their image, they have to rely on patchwork of causes of action including passing off, copyright, misuse of private information and data protection.” With no major standardized legislation, I believe it is easily argued that the US has the greater legislation in this area by providing more consistent care to these victims.

## Copyright and Intellectual Property

To expand further, copyright and intellectual property law will be using mainly US congressional report, LSB10922 (legal side bar), which designates the rights of a human in the production of AI generated art, as well as the implication of infringement from the art generation itself since it has been trained on other artist’s work (Zirpoli). 

To elaborate, LSB10922 describes that human creativity must be required to obtain a copyright on a work. One exception of AI use in copyrightable work is possibly photography in which if the photographer is making decisions about the physical arrangement of subjects and settings of the camera and then uses AI in editing, it could be seen as just another type of tool since they were still active in every part of creation. They also determine that an artist may claim copyright if their work was found to be in the training data for the art generation model and even have their works removed from the model's training data in the future; there is so much controversy in the art world about machine learning algorithms stealing their artwork to be used in training data that University of Chicago has led a team of researchers to develop a computer program called Nightshade specifically designed to “poison artificial intelligence models,” and has even been “downloaded more than 250,000 times [in five days]” (Schrader). Art theft in this manner is a great point of contention between artists and developers. 

Similarly, the distinction of art being a human act was a point for Dr. Simon Hembt, a doctor of legal studies with a special focus on European law and Intellectual Property Law, who helpfully notes that according to the European Court of Justice, "a 'work' is an independent concept when the following two criteria are met: it must represent an original intellectual creation of its author, and only elements expressing such a creation should be considered as a 'work,'" creating a massive precedent for the intellectual rights to generative artificial intelligence works. Given both sides devoted protection of artists rights, I would assert that there is negligible difference between effectiveness between the United States and European Union’s legislation regarding copyright and intellectual property.

## Scams, Fraud, and Phishing

Finally, scams, fraud, and phishing will reference H. R. 5586 and a Europol article and presentation expressing their concerns about AI's capabilities in fraud, phishing, and cybercrime. In this case, H. R. 5586 does not contain prominent language in defining the terms of fraudulent action with AI. However, it does address the threat by including clauses to ensure that any AI-generated content will be required to include some indication that it is not real including not less than one verbal statement of altered audio and visual elements, unobscured written statement in clear, readable text, or an icon to signal that generative AI has altered the content. In contrast, the Europol article and presentation dive deeply into the terrifyingly prominent threat of fraud, social engineering, disinformation, and cybercrime. Their main worries about ChatGPT's "ability to draft highly realistic text makes it a useful tool for phishing purposes. …impersonate the style of speech of specific individuals or groups," as well as "propaganda and disinformation purposes…with relatively little effort… [making it an] invaluable resource to produce malicious code" (Europol, "The Criminal Use of ChatGPT – a Cautionary Tale about Large Language Models.").

Phishing is a growing issue with the advent of rapid, international, low regulation communication. This growth has only been accelerated by the creation of machine learning; across the world, this sector of cybercrime causes over six trillion united states dollars a year of damages; between online scams, ransomware, trojan horse viruses, and purely damage-inducing malware, these are becoming an all to present threat (Morgan). There are many ways of abusing machine learning algorithms to harm people; Europol’s greatest worries are fraud and social engineering, disinformation, and of course cybercrime. Firstly, fraud and social engineering is a great worry due to the effectiveness and speed of generative artificial intelligence algorithms. In addition to their speed and effectiveness, it also has the ability to mimic many characteristics of specific people’s speech such as their style, tone, intonation, etc. The danger being, “this capability can be abused at scale to mislead potential victims into placing their trust in the hands of criminal actors,” (Europol) by creating fake hostage situations, family or friends asking for help, and much more. Disinformation has also been a very present worry for the public with bad actors using machine learning algorithms abilities to on it “[produce] authentic sounding text at speed and scale,” this usage, “makes the model ideal for propaganda.” Lastly, is the capability of machine learning algorithms to create mass waves of cybercrime by allowing anyone with access to the model to generate practically unlimited malicious scripts. Since, these models were trained on many different sources, they have access to many programming languages are able to generate efficient, easy to distribute code; in the EU’s words, “for a potential criminal with little technical knowledge, this is an invaluable resource to produce malicious code.” Additionally, as these models are further advanced, they will become better at processing and synthesizing data, creating fewer barriers to entry for criminals. 

Given the difficulty in creating capable models while not being able to directly affect the black box algorithms, there seems to be only one major approach to regulating this type of generated content. The United States and European Union are both greatly considering adopting transparency laws which would force either generators or those who release generated content to also have some type of visual or audible disclosure that it was artificially generated. In the US, H.R. 5586 gives guidelines for disclosures, namely,  “any advanced technological false personation records containing both an audio and a visual element shall include,” all of the following: no less than one verbal statement that identifies it as being altered, an unobscured written statement in readable text as well as a record and description of the alterations, and an icon to signal that the content was a production of some of machine learning algorithm. On a similar note, the European Union’s AI act will necessitate that automated systems such as chatbots will require some type of disclosure to the human subject that the system they are using is not human so that the person may make their own choice on how to continue. This act also institutes similar disclosures on other content: generated text, video, or audio (European Commission). Thus, I would consider that since machine generated content is such a large threat in our society, that stricter regulations would be considered more appropriate, and that in this scenario, that while the EU does implement good checks on this type of work, the United States has much more protection overall.

## Conclusion

Overall, the United States has been shown to prioritize people’s safety across the three most prominent and damaging areas of interest: falsified image generation such as explicit deepfakes as well as other types of non-explicit but misleading image or text generation, protecting artist rights by allowing artists to retaliate against corporations using their works for algorithm training while also not allowing art without extensive creative direction in the development of the work to be copyrightable, and protecting against the ever-growing threat of phishing, especially as the world moves further and further into the digital realm. In two of these three main designations, the United States’s legislation has matched or even surpassed the performance of the European Union.

